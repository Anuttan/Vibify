name: Data Pipeline

on:
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  LOCATION: "us-east1"
  ENVIRONMENT_NAME: "data-pipeline"

jobs:
  deploy-and-run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Google Auth
        id: auth
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Configure gcloud project
        run: |
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}

      - name: Enable required APIs
        run: |
          gcloud services enable composer.googleapis.com
          gcloud services enable artifactregistry.googleapis.com

      - name: Check/Create Cloud Composer Environment
        run: |
          if [[ -n "$(gcloud composer environments list --locations=${{ env.LOCATION }} --project=vibify-demo --filter="name:${{ env.ENVIRONMENT_NAME }}" --format="get(name)")" ]]; then
            echo "Environment ${{ env.ENVIRONMENT_NAME }} already exists"
          else
            gcloud composer environments create ${{ env.ENVIRONMENT_NAME }} \
              --location=${{ env.LOCATION }} \
              --project=vibify-demo \
              --image-version=composer-3-airflow-2.10.2-build.0 \
              --service-account=751083964065-compute@developer.gserviceaccount.com \
              --environment-size=small \
              --scheduler-cpu=0.5 \
              --scheduler-memory=1 \
              --scheduler-storage=1 \
              --web-server-cpu=0.5 \
              --web-server-memory=1 \
              --web-server-storage=1 \
              --worker-cpu=0.5 \
              --worker-memory=1 \
              --worker-storage=1 \
              --min-workers=1 \
              --max-workers=3 \
              --storage-bucket vibe-demo-bucket 
          fi

      - name: Create Git Init Script
        run: |
          echo '#!/bin/bash
          cd /home/airflow
          git init
          git config --global --add safe.directory /home/airflow' > pipelines/dags/git_init.sh

      - name: Create Git Init DAG
        run: |
          echo 'from airflow import DAG
          from airflow.operators.bash_operator import BashOperator
          from datetime import datetime
          
          dag = DAG(
              "git_init",
              start_date=datetime(2024, 1, 1),
              schedule_interval=None
          )
          
          git_init = BashOperator(
              task_id="git_init",
              bash_command="bash /home/airflow/gcs/dags/git_init.sh",
              dag=dag
          )' > pipelines/dags/git_init.py

      - name: Check and Install Python Dependencies
        run: |
          # Get current packages
          CURRENT_PACKAGES=$(gcloud composer environments describe ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            --format="get(config.softwareConfig.pypiPackages)")
          
          # Read required packages
          REQUIRED_PACKAGES=$(cat pipelines/dags/requirements.txt)
          
          # Check if any package is missing
          MISSING=false
          while IFS= read -r package; do
            if ! echo "$CURRENT_PACKAGES" | grep -q "$(echo $package | cut -d'=' -f1)"; then
              MISSING=true
              break
            fi
          done <<< "$REQUIRED_PACKAGES"
          
          if [ "$MISSING" = true ]; then
            echo "Installing missing Python dependencies"
            gcloud composer environments update ${{ env.ENVIRONMENT_NAME }} \
              --location=${{ env.LOCATION }} \
              --project=vibify-demo \
              --update-pypi-packages-from-file pipelines/dags/requirements.txt
          else
            echo "All required packages are already installed"
          fi

      - name: Get Composer GCS bucket
        id: get-bucket
        run: |
          DAGS_BUCKET=$(gcloud composer environments describe ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            --format="get(config.dagGcsPrefix)" | sed 's/\/dags//')
          echo "DAGS_BUCKET=$DAGS_BUCKET" >> $GITHUB_ENV

      - name: Copy DAGs folder to GCS
        run: |
          gsutil -m cp -r pipelines/dags/* ${{ env.DAGS_BUCKET }}/dags/

      - name: List uploaded DAGs
        run: |
          echo "Listing contents of DAGs folder in GCS:"
          gsutil ls -r ${{ env.DAGS_BUCKET }}/dags/

      - name: Set Airflow Variables
        run: |
          # Wait for environment to be ready
          sleep 300
          
          # Set Git environment variable
          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            variables set -- GCS_BUCKET_NAME "${{ env.DAGS_BUCKET }}"
          
          # Set each variable in Airflow
          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            variables set -- GCP_PROJECT_ID ${{ secrets.GCP_PROJECT_ID }}

          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            variables set -- SLACK_WEBHOOK_URL "${{ secrets.SLACK_WEBHOOK_URL }}"

      - name: Trigger Git Init DAG
        run: |
          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            dags trigger -- git_init

      - name: Wait for Git Init
        run: sleep 60

      - name: Trigger Main DAG
        run: |
          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            dags trigger -- data_pipeline

      - name: Delete Cloud Composer Environment
        run: |
          sleep 300 # To see that the dag works properly and to show in video
          gcloud composer environments delete ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --project=vibify-demo \
            --quiet