name: Data Pipeline

on:
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  LOCATION: "us-east1"
  ENVIRONMENT_NAME: "data-pipeline"

jobs:
  deploy-and-run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Google Auth
        id: auth
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Enable required APIs
        run: |
          gcloud services enable composer.googleapis.com
          gcloud services enable artifactregistry.googleapis.com

      - name: Check if environment exists
        id: check-env
        continue-on-error: true
        run: |
          gcloud composer environments describe ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }}

      - name: Create Cloud Composer Environment
        if: steps.check-env.outcome == 'failure'
        run: |
          gcloud composer environments create ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --image-version=composer-2.5.3-airflow-2.5.3 \
            --python-version=3

      - name: Wait for environment readiness
        if: steps.check-env.outcome == 'failure'
        run: |
          echo "Waiting for environment to be ready..."
          while [[ $(gcloud composer environments describe ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --format="get(state)") != "RUNNING" ]]; do
            sleep 60
          done

      - name: Get Composer GCS bucket
        id: get-bucket
        run: |
          DAGS_BUCKET=$(gcloud composer environments describe ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            --format="get(config.dagGcsPrefix)" | sed 's/\/dags//')
          echo "DAGS_BUCKET=$DAGS_BUCKET" >> $GITHUB_ENV

      - name: Clear existing DAGs
        run: |
          gsutil -m rm -rf ${{ env.DAGS_BUCKET }}/dags/* || true

      - name: Copy DAGs folder to GCS
        run: |
          gsutil -m cp -r pipelines/dags/* ${{ env.DAGS_BUCKET }}/dags/

      - name: List uploaded DAGs
        run: |
          echo "Listing contents of DAGs folder in GCS:"
          gsutil ls -r ${{ env.DAGS_BUCKET }}/dags/

      - name: Trigger DAG
        run: |
          gcloud composer environments run ${{ env.ENVIRONMENT_NAME }} \
            --location=${{ env.LOCATION }} \
            dags trigger -- data_pipeline